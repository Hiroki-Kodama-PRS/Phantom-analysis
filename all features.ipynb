{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f77400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.signal import find_peaks, detrend, butter, filtfilt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import math\n",
    "from scipy.fft import rfftfreq, rfft # AUC計算コードには不要だが、元のコードのimportを維持\n",
    "\n",
    "# ========= 基本設定 =========\n",
    "fs = 2000  # Hz\n",
    "depths = [3, 9, 15, 21]\n",
    "state_map = {1: \"Normal\", 2: \"Ischaemia\", 3: \"Congestion\"}\n",
    "channels = {\"ppgA_Red_AGC\": \"Red\", \"ppgA_IR_AGC\": \"IR\"} \n",
    "DEBUG_MODE = True\n",
    "DEBUG_FILE = \"debug_log_part1_to_3_time_features_norm.txt\"\n",
    "with open(DEBUG_FILE, \"w\") as f:\n",
    "    f.write(\"--- Debug Log Start (Time Features BPM Norm) ---\\n\")\n",
    "\n",
    "def DEBUG_LOG(message):\n",
    "    if DEBUG_MODE:\n",
    "        with open(DEBUG_FILE, \"a\") as f:\n",
    "            f.write(message + \"\\n\")\n",
    "        # print(message)\n",
    "\n",
    "# --- BPF, BPM推定関数 (変更なし) ---\n",
    "def bandpass_filter(sig, fs, low=0.5, high=5.0, order=3):\n",
    "    nyq = fs / 2\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n",
    "    return filtfilt(b, a, sig)\n",
    "\n",
    "def estimate_bpm(signal, fs=2000):\n",
    "    sig = pd.Series(signal, dtype=float).interpolate().fillna(0).values\n",
    "    sig = detrend(sig)\n",
    "    sig = bandpass_filter(sig, fs)\n",
    "    prom = max(np.std(sig) * 0.3, np.ptp(sig) * 0.05)\n",
    "    peaks, _ = find_peaks(sig, prominence=prom, distance=int(fs * 0.5))\n",
    "    if len(peaks) < 2:\n",
    "        return np.nan\n",
    "    duration_sec = len(sig) / fs\n",
    "    bpm = len(peaks) / (duration_sec / 60.0)\n",
    "    return bpm\n",
    "\n",
    "# --- 1拍ごとの特徴抽出 (ロバスト性向上) ---\n",
    "def extract_pulse_features(signal, fs, dist=0.3):\n",
    "    threshold_height = np.min(signal) + (np.ptp(signal) * 0.1)\n",
    "    peaks, _ = find_peaks(signal, height=threshold_height, distance=int(fs * dist))\n",
    "    \n",
    "    feats = []\n",
    "    if len(peaks) < 2: return []\n",
    "        \n",
    "    for p in peaks:\n",
    "        left = max(0, p - int(0.5 * fs))\n",
    "        right = min(len(signal), p + int(0.5 * fs))\n",
    "        seg = signal[left:right]\n",
    "        if len(seg) < 5: continue\n",
    "        if np.any(np.isnan(seg)) or np.all(seg == seg[0]): continue\n",
    "        \n",
    "        peak_idx = np.argmax(seg)\n",
    "        trough_idx = np.argmin(seg[:peak_idx+1])\n",
    "        next_trough_idx = peak_idx + np.argmin(seg[peak_idx:])\n",
    "        \n",
    "        if trough_idx < peak_idx < next_trough_idx:\n",
    "            \n",
    "            rise = (peak_idx - trough_idx) / fs\n",
    "            fall = (next_trough_idx - peak_idx) / fs\n",
    "            baseline = seg[trough_idx]\n",
    "            peak_val = seg[peak_idx]\n",
    "            amp = peak_val - baseline\n",
    "            half = baseline + 0.5 * amp\n",
    "            \n",
    "            # Pulse Width (PW)\n",
    "            seg_pw = seg[trough_idx:next_trough_idx+1]\n",
    "            above_half = np.where(seg_pw >= half)[0]\n",
    "            pw = (above_half[-1] - above_half[0]) / fs if len(above_half) > 1 else np.nan\n",
    "            \n",
    "            # Systolic Width (SW)\n",
    "            systolic_seg = seg[trough_idx:peak_idx+1]\n",
    "            sys_above_half = np.where(systolic_seg >= half)[0]\n",
    "            sw = (sys_above_half[-1] - sys_above_half[0]) / fs if len(sys_above_half) > 1 else np.nan\n",
    "            \n",
    "            # Diastolic Width (DW)\n",
    "            diastolic_seg = seg[peak_idx:next_trough_idx+1]\n",
    "            dias_above_half = np.where(diastolic_seg >= half)[0]\n",
    "            dw = (dias_above_half[-1] - dias_above_half[0]) / fs if len(dias_above_half) > 1 else np.nan\n",
    "            \n",
    "            feats.append((rise, fall, pw, amp, sw, dw))\n",
    "    return feats\n",
    "\n",
    "# ========= Part 1 & 2: データロードと特徴抽出 =========\n",
    "records = []\n",
    "pulse_id_counter = 0 \n",
    "\n",
    "for depth in depths:\n",
    "    for i_state, state_name in state_map.items():\n",
    "        file_path = Path(f\"{depth}mm_AGC_data{i_state}.csv\")\n",
    "        DEBUG_LOG(f\"\\n--- Processing: {file_path.name} ({state_name}) ---\")\n",
    "\n",
    "        if not file_path.exists(): continue\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # --- BPM推定 ---\n",
    "        ir_sig = df.get(\"ppgA_IR_AGC\", pd.Series([]).values)\n",
    "        if len(ir_sig) == 0: continue\n",
    "            \n",
    "        bpm = estimate_bpm(ir_sig, fs)\n",
    "        window_sec = 60.0 / bpm if not np.isnan(bpm) and bpm > 0 else 1.0\n",
    "        window_sec = float(np.clip(window_sec, 0.6, 2.0))\n",
    "        \n",
    "        step = int(round(fs * window_sec))\n",
    "        current_pulse_id = pulse_id_counter \n",
    "\n",
    "        for col, ch_label in channels.items():\n",
    "            if col not in df.columns: continue\n",
    "            sig = df[col].values\n",
    "\n",
    "            # (1) Window-based Amplitude \n",
    "            n_win = len(sig) // step\n",
    "            DEBUG_LOG(f\"  Channel: {ch_label}, Total Windows: {n_win}\")\n",
    "            \n",
    "            for w in range(n_win):\n",
    "                s, e = w * step, (w + 1) * step\n",
    "                seg = sig[s:e]\n",
    "                if len(seg) < 5: continue\n",
    "                amp = seg.max() - seg.min()\n",
    "                \n",
    "                # ★修正: Time featuresのみに限定するため、Amplitudeはここでは記録しない\n",
    "                pass\n",
    "\n",
    "            # (2) peaksで詳細特徴抽出 (Peak-based)\n",
    "            feats = extract_pulse_features(sig, fs)\n",
    "            DEBUG_LOG(f\"  Channel: {ch_label}, Extracted Pulse Features: {len(feats)} pulses.\")\n",
    "            \n",
    "            for rise, fall, pw, amp, sw, dw in feats:\n",
    "                # ★★★ BPM値とPulse Intervalを格納 ★★★\n",
    "                records.append({\n",
    "                    \"Depth\": depth, \"State\": state_name, \"Channel\": ch_label,\n",
    "                    \"Pulse_ID\": current_pulse_id,\n",
    "                    \"RiseTime\": rise, \n",
    "                    \"FallTime\": fall,\n",
    "                    \"PulseWidth\": pw, \n",
    "                    \"Amplitude\": amp,\n",
    "                    \"SystolicWidth\": sw, \n",
    "                    \"DiastolicWidth\": dw, \n",
    "                    \"BPM\": bpm,\n",
    "                    \"PulseInterval\": window_sec # Pulse Interval = Window Sec\n",
    "                })\n",
    "        \n",
    "        pulse_id_counter += 1 \n",
    "\n",
    "df_feat = pd.DataFrame(records)\n",
    "if df_feat.empty:\n",
    "    raise RuntimeError(\"Error: No data loaded. Please check CSV files.\")\n",
    "\n",
    "\n",
    "# ========= Part 3: 複合指標と正規化 (時間特徴に特化) =========\n",
    "\n",
    "# ★★★ 修正: BPM正規化された時間的特徴量の計算 ★★★\n",
    "time_features = [\"RiseTime\", \"FallTime\", \"PulseWidth\", \"SystolicWidth\", \"DiastolicWidth\"]\n",
    "\n",
    "for f in time_features:\n",
    "    # PulseIntervalで除算し、BPM依存性を除去\n",
    "    df_feat[f\"{f}_norm_bpm\"] = df_feat[f] / df_feat[\"PulseInterval\"]\n",
    "\n",
    "# 複合指標の計算 (BPM正規化後の特徴量を使用)\n",
    "df_feat[\"RiseFall_ratio\"] = df_feat[\"FallTime\"] / (df_feat[\"RiseTime\"] + 1e-6) # BPM正規化は不要 (比率のため)\n",
    "df_feat[\"Width_Ratio\"] = df_feat[\"DiastolicWidth\"] / (df_feat[\"SystolicWidth\"] + 1e-6) # BPM正規化は不要 (比率のため)\n",
    "\n",
    "DEBUG_LOG(f\"\\n--- Part 3 Complete: BPM Normalized Time Features Created ---\")\n",
    "\n",
    "\n",
    "# --- Red/IR比 (マージロジックのみ使用) ---\n",
    "amp_data = df_feat.dropna(subset=['Amplitude']).copy()\n",
    "\n",
    "# マージに必要なカラムリスト (正規化後の時間特徴量を含む)\n",
    "merge_cols = ['Depth', 'State', 'Pulse_ID'] + time_features + [f\"{f}_norm_bpm\" for f in time_features] + [\"RiseFall_ratio\", \"Width_Ratio\"] + ['Amplitude']\n",
    "\n",
    "\n",
    "df_red = amp_data[amp_data.Channel == \"Red\"][merge_cols].rename(\n",
    "    columns={\"Amplitude\": \"Amplitude_Red\"}\n",
    ")\n",
    "\n",
    "df_ir = amp_data[amp_data.Channel == \"IR\"][merge_cols].rename(\n",
    "    columns={\"Amplitude\": \"Amplitude_IR\"}\n",
    ")\n",
    "\n",
    "df_ratio = pd.merge(df_red, df_ir, on=['Depth','State','Pulse_ID'], how='inner', suffixes=('_Red', '_IR'))\n",
    "DEBUG_LOG(f\"Ratio Data Rows (Merged for Time Features): {len(df_ratio)}\")\n",
    "\n",
    "\n",
    "# ========= Part 4: ROC AUC計算 (時間特徴に限定) =========\n",
    "pairs = [(\"Normal\",\"Ischaemia\"),(\"Normal\",\"Congestion\"),(\"Ischaemia\",\"Congestion\")]\n",
    "\n",
    "# ★★★ 評価対象の特徴量リストを更新 ★★★\n",
    "features_to_eval = [\n",
    "    \"RiseTime\", \"FallTime\", \"PulseWidth\", \"SystolicWidth\", \"DiastolicWidth\",\n",
    "    \"RiseTime_norm_bpm\", \"FallTime_norm_bpm\", \"PulseWidth_norm_bpm\", \n",
    "    \"SystolicWidth_norm_bpm\", \"DiastolicWidth_norm_bpm\",\n",
    "    \"RiseFall_ratio\", \"Width_Ratio\"\n",
    "] \n",
    "\n",
    "# AUC Bootstrap Helper (再定義)\n",
    "def bootstrap_auc_ci(y_true, y_score, n_bootstrap=200):\n",
    "    rng = np.random.default_rng(42)\n",
    "    aucs=[]\n",
    "    n=len(y_true)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.integers(0,n,n)\n",
    "        if len(np.unique(y_true[idx]))<2 or np.all(y_score[idx]==y_score[idx][0]): continue\n",
    "        aucs.append(roc_auc_score(y_true[idx],y_score[idx]))\n",
    "    if not aucs: return np.nan,np.nan,np.nan\n",
    "    return np.mean(aucs), np.percentile(aucs,2.5), np.percentile(aucs,97.5)\n",
    "\n",
    "\n",
    "rows=[]\n",
    "# Channel-specific features\n",
    "for ch in [\"Red\",\"IR\"]:\n",
    "    for depth in depths:\n",
    "        sub = df_feat[(df_feat.Channel==ch)&(df_feat.Depth==depth)]\n",
    "        if sub.empty: continue\n",
    "        for f in features_to_eval:\n",
    "            for c1,c2 in pairs:\n",
    "                d=sub[sub.State.isin([c1,c2])]\n",
    "                if d.empty: continue\n",
    "                y_true=(d.State==c1).astype(int).values\n",
    "                y_score=d[f].values\n",
    "                mask=~np.isnan(y_score)\n",
    "                y_true=y_true[mask]; y_score=y_score[mask]\n",
    "                \n",
    "                n_samples_used = len(y_true)\n",
    "                if n_samples_used < 5 or len(np.unique(y_true))<2: \n",
    "                    DEBUG_LOG(f\"[WARN] {ch} {depth}mm {c1} vs {c2} ({f}): Insufficient samples ({n_samples_used}) or classes.\")\n",
    "                    continue\n",
    "                \n",
    "                # (AUC計算ロジックは変更なし)\n",
    "                auc=roc_auc_score(y_true,y_score)\n",
    "                auc_bs,ci_lo,ci_hi=bootstrap_auc_ci(y_true,y_score)\n",
    "                fpr,tpr,thr=roc_curve(y_true,y_score)\n",
    "                youden=tpr-fpr; idx=np.argmax(youden)\n",
    "                cutoff_val = thr[idx]\n",
    "                if np.isinf(cutoff_val) or np.isnan(cutoff_val):\n",
    "                    DEBUG_LOG(f\"[ERROR] {ch} {depth}mm {c1} vs {c2} ({f}): Cutoff is {cutoff_val}. Samples={n_samples_used}\")\n",
    "\n",
    "                rows.append({\"Channel\":ch,\"Depth\":depth,\"Feature\":f,\"Pair\":f\"{c1} vs {c2}\",\n",
    "                             \"AUC_bootstrap_mean\":auc_bs,\"CI_lower\":ci_lo,\"CI_upper\":ci_hi,\"n_samples\":n_samples_used})\n",
    "\n",
    "# Ratio features (今回は時間特徴のみのため、Ratioは計算対象外)\n",
    "# Time Ratio Features (e.g., RiseFall_ratio_Red/IR) は時間特徴ではないため、ここでは計算しない\n",
    "\n",
    "df_auc_feat = pd.DataFrame(rows)\n",
    "df_auc_feat.to_csv(\"AUC_time_features_bpm_norm.csv\", index=False)\n",
    "DEBUG_LOG(\"--- Part 4 Complete: AUC calculation for Time Features (BPM Norm) saved. ---\")\n",
    "print(\"✅ Time features AUC analysis (BPM Normalized) complete. Check AUC_time_features_bpm_norm.csv and log file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfec97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.signal import find_peaks, detrend, butter, filtfilt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import math\n",
    "from scipy.fft import rfftfreq, rfft \n",
    "\n",
    "# ========= 基本設定 =========\n",
    "fs = 2000  # Hz\n",
    "depths = [3, 9, 15, 21]\n",
    "state_map = {1: \"Normal\", 2: \"Ischaemia\", 3: \"Congestion\"}\n",
    "channels = {\"ppgA_Red_AGC\": \"Red\", \"ppgA_IR_AGC\": \"IR\"} \n",
    "DEBUG_MODE = True\n",
    "DEBUG_FILE = \"debug_log_part1_to_3_amplitude_features.txt\"\n",
    "with open(DEBUG_FILE, \"w\") as f:\n",
    "    f.write(\"--- Debug Log Start (Amplitude & Area Features) ---\\n\")\n",
    "\n",
    "def DEBUG_LOG(message):\n",
    "    if DEBUG_MODE:\n",
    "        with open(DEBUG_FILE, \"a\") as f:\n",
    "            f.write(message + \"\\n\")\n",
    "\n",
    "# --- BPF, BPM推定関数 (変更なし) ---\n",
    "def bandpass_filter(sig, fs, low=0.5, high=5.0, order=3):\n",
    "    nyq = fs / 2\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n",
    "    return filtfilt(b, a, sig)\n",
    "\n",
    "def estimate_bpm(signal, fs=2000):\n",
    "    sig = pd.Series(signal, dtype=float).interpolate().fillna(0).values\n",
    "    sig = detrend(sig)\n",
    "    sig = bandpass_filter(sig, fs)\n",
    "    prom = max(np.std(sig) * 0.3, np.ptp(sig) * 0.05)\n",
    "    peaks, _ = find_peaks(sig, prominence=prom, distance=int(fs * 0.5))\n",
    "    if len(peaks) < 2:\n",
    "        return np.nan\n",
    "    duration_sec = len(sig) / fs\n",
    "    bpm = len(peaks) / (duration_sec / 60.0)\n",
    "    return bpm\n",
    "\n",
    "# --- ★★★ 1拍ごとの特徴抽出 (面積特徴量計算を追加) ★★★\n",
    "def extract_pulse_features(signal, fs, dist=0.3):\n",
    "    # ロバスト性向上のためのピーク検出閾値 (信号振幅の10%以上の高さを要求)\n",
    "    threshold_height = np.min(signal) + (np.ptp(signal) * 0.1)\n",
    "    peaks, _ = find_peaks(signal, height=threshold_height, distance=int(fs * dist))\n",
    "    \n",
    "    feats = []\n",
    "    if len(peaks) < 2: return []\n",
    "        \n",
    "    for p in peaks:\n",
    "        left = max(0, p - int(0.5 * fs))\n",
    "        right = min(len(signal), p + int(0.5 * fs))\n",
    "        seg = signal[left:right]\n",
    "        if len(seg) < 5: continue\n",
    "        if np.any(np.isnan(seg)) or np.all(seg == seg[0]): continue\n",
    "        \n",
    "        peak_idx = np.argmax(seg)\n",
    "        trough_idx = np.argmin(seg[:peak_idx+1])\n",
    "        next_trough_idx = peak_idx + np.argmin(seg[peak_idx:])\n",
    "        \n",
    "        if trough_idx < peak_idx < next_trough_idx:\n",
    "            \n",
    "            # --- 共通の基線と振幅の計算 ---\n",
    "            baseline = seg[trough_idx]\n",
    "            peak_val = seg[peak_idx]\n",
    "            amp = peak_val - baseline\n",
    "            \n",
    "            # Pulse Area (全面積)\n",
    "            full_seg = seg[trough_idx:next_trough_idx+1]\n",
    "            # np.trapz(y, dx) で台形則による面積を計算\n",
    "            area_pulse = np.trapz(full_seg - baseline, dx=1/fs) \n",
    "            \n",
    "            # --- 面積特徴量の計算 (S-AUC, D-AUC) ---\n",
    "            # S-AUC: 収縮期面積 (トラフからピークまで)\n",
    "            sys_seg = seg[trough_idx:peak_idx+1]\n",
    "            area_systolic = np.trapz(sys_seg - baseline, dx=1/fs)\n",
    "            \n",
    "            # D-AUC: 拡張期面積 (ピークから次のトラフまで)\n",
    "            dias_seg = seg[peak_idx:next_trough_idx+1]\n",
    "            area_diastolic = np.trapz(dias_seg - baseline, dx=1/fs)\n",
    "            \n",
    "            feats.append((area_pulse, area_systolic, area_diastolic, amp))\n",
    "    return feats\n",
    "\n",
    "# ========= Part 1 & 2: データロードと特徴抽出 =========\n",
    "records = []\n",
    "pulse_id_counter = 0 \n",
    "\n",
    "for depth in depths:\n",
    "    for i_state, state_name in state_map.items():\n",
    "        file_path = Path(f\"{depth}mm_AGC_data{i_state}.csv\")\n",
    "        DEBUG_LOG(f\"\\n--- Processing: {file_path.name} ({state_name}) ---\")\n",
    "\n",
    "        if not file_path.exists(): continue\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # --- BPM推定 ---\n",
    "        ir_sig = df.get(\"ppgA_IR_AGC\", pd.Series([]).values)\n",
    "        if len(ir_sig) == 0: continue\n",
    "            \n",
    "        bpm = estimate_bpm(ir_sig, fs)\n",
    "        window_sec = 60.0 / bpm if not np.isnan(bpm) and bpm > 0 else 1.0\n",
    "        window_sec = float(np.clip(window_sec, 0.6, 2.0))\n",
    "        \n",
    "        step = int(round(fs * window_sec))\n",
    "        current_pulse_id = pulse_id_counter \n",
    "\n",
    "        for col, ch_label in channels.items():\n",
    "            if col not in df.columns: continue\n",
    "            sig = df[col].values\n",
    "\n",
    "            # (1) Window-based Amplitude (Amplitudeのサンプリングを増やす目的で維持)\n",
    "            n_win = len(sig) // step\n",
    "            DEBUG_LOG(f\"  Channel: {ch_label}, Total Windows: {n_win}\")\n",
    "            \n",
    "            for w in range(n_win):\n",
    "                s, e = w * step, (w + 1) * step\n",
    "                seg = sig[s:e]\n",
    "                if len(seg) < 5: continue\n",
    "                amp = seg.max() - seg.min()\n",
    "                \n",
    "                records.append({\n",
    "                    \"Depth\": depth, \"State\": state_name, \"Channel\": ch_label,\n",
    "                    \"Pulse_ID\": current_pulse_id,\n",
    "                    \"Amplitude\": amp,\n",
    "                    \"Pulse_Area\": np.nan, \"S_AUC\": np.nan, \"D_AUC\": np.nan\n",
    "                })\n",
    "\n",
    "            # (2) peaksで詳細特徴抽出 (Peak-based)\n",
    "            feats = extract_pulse_features(sig, fs)\n",
    "            DEBUG_LOG(f\"  Channel: {ch_label}, Extracted Pulse Features: {len(feats)} pulses.\")\n",
    "            \n",
    "            for area_pulse, area_systolic, area_diastolic, amp in feats:\n",
    "                # 振幅と面積特徴量のみを記録\n",
    "                records.append({\n",
    "                    \"Depth\": depth, \"State\": state_name, \"Channel\": ch_label,\n",
    "                    \"Pulse_ID\": current_pulse_id,\n",
    "                    \"Amplitude\": amp,\n",
    "                    \"Pulse_Area\": area_pulse,\n",
    "                    \"S_AUC\": area_systolic,\n",
    "                    \"D_AUC\": area_diastolic,\n",
    "                })\n",
    "        \n",
    "        pulse_id_counter += 1 \n",
    "\n",
    "df_feat = pd.DataFrame(records)\n",
    "if df_feat.empty:\n",
    "    raise RuntimeError(\"Error: No data loaded. Please check CSV files.\")\n",
    "DEBUG_LOG(f\"\\n--- Part 2 Complete: Total Feature Rows: {len(df_feat)} ---\")\n",
    "\n",
    "\n",
    "# ========= Part 3: 複合指標と正規化 (振幅・面積特徴に特化) =========\n",
    "# Area Under Curve Ratio (Ratio between systolic and diastolic areas)\n",
    "df_feat[\"AUC_Ratio\"] = df_feat[\"S_AUC\"] / (df_feat[\"D_AUC\"] + 1e-6)\n",
    "\n",
    "\n",
    "# --- 正規化（Redは3mm Red Normal基準、IRは3mm IR Normal基準） ---\n",
    "# Amplitudeの正規化\n",
    "def normalize_channel_amp(df, ch):\n",
    "    base_data = df.query(\"Channel==@ch and Depth==3 and State=='Normal'\")[\"Amplitude\"]\n",
    "    base = base_data.mean()\n",
    "    DEBUG_LOG(f\"Normalization Base (Amplitude, {ch}): Mean={base:.4e}, Count={len(base_data)}\")\n",
    "    \n",
    "    if pd.isna(base) or base == 0:\n",
    "        df.loc[df.Channel == ch, \"Amp_norm\"] = np.nan\n",
    "    else:\n",
    "        df.loc[df.Channel == ch, \"Amp_norm\"] = df.loc[df.Channel == ch, \"Amplitude\"] / base\n",
    "\n",
    "normalize_channel_amp(df_feat, \"Red\")\n",
    "normalize_channel_amp(df_feat, \"IR\")\n",
    "\n",
    "# 面積特徴量の正規化\n",
    "area_features = [\"Pulse_Area\", \"S_AUC\", \"D_AUC\"]\n",
    "\n",
    "for f in area_features:\n",
    "    def normalize_channel_area(df, ch, feature):\n",
    "        base_data = df.query(\"Channel==@ch and Depth==3 and State=='Normal'\")[feature]\n",
    "        base = base_data.mean()\n",
    "        \n",
    "        DEBUG_LOG(f\"Normalization Base ({feature}, {ch}): Mean={base:.4e}, Count={len(base_data)}\")\n",
    "        \n",
    "        if pd.isna(base) or base == 0:\n",
    "            df.loc[df.Channel == ch, f\"{feature}_norm\"] = np.nan\n",
    "        else:\n",
    "            df.loc[df.Channel == ch, f\"{feature}_norm\"] = df.loc[df.Channel == ch, feature] / base\n",
    "            \n",
    "    normalize_channel_area(df_feat, \"Red\", f)\n",
    "    normalize_channel_area(df_feat, \"IR\", f)\n",
    "\n",
    "\n",
    "# --- Red/IR比 ---\n",
    "# Amplitudeと面積の正規化された比率を計算 (Red/IR_Ratio)\n",
    "\n",
    "amp_data = df_feat.dropna(subset=['Amplitude', 'Amp_norm']).copy()\n",
    "\n",
    "df_red = amp_data[amp_data.Channel == \"Red\"].rename(\n",
    "    columns={\"Amplitude\": \"Amplitude_Red\", \"Amp_norm\": \"Amp_norm_Red\"}\n",
    ")[['Depth', 'State', 'Pulse_ID', 'Amp_norm_Red'] + [f\"{f}_norm\" for f in area_features]]\n",
    "\n",
    "df_ir = amp_data[amp_data.Channel == \"IR\"].rename(\n",
    "    columns={\"Amplitude\": \"Amplitude_IR\", \"Amp_norm\": \"Amp_norm_IR\"}\n",
    ")[['Depth', 'State', 'Pulse_ID', 'Amp_norm_IR'] + [f\"{f}_norm\" for f in area_features]]\n",
    "\n",
    "df_ratio = pd.merge(df_red, df_ir, on=['Depth','State','Pulse_ID'], how='inner', suffixes=('_Red', '_IR'))\n",
    "DEBUG_LOG(f\"Ratio Data Rows (Merged for Amplitude/Area): {len(df_ratio)}\")\n",
    "\n",
    "# Red/IR Ratio 特徴量の計算\n",
    "df_ratio[\"Red_IR_amp_norm_ratio\"] = df_ratio[\"Amp_norm_Red\"] / (df_ratio[\"Amp_norm_IR\"] + 1e-6)\n",
    "\n",
    "# ★★★ 修正箇所: 面積のRed/IR比の列名計算 (KeyError対策) ★★★\n",
    "for f in area_features:\n",
    "    # 列名に_normを付けて、評価リスト(ratio_features_to_eval)と一致させる\n",
    "    df_ratio[f\"{f}_norm_ratio\"] = df_ratio[f\"{f}_norm_Red\"] / (df_ratio[f\"{f}_norm_IR\"] + 1e-6)\n",
    "# ★★★ (修正完了) ★★★\n",
    "\n",
    "\n",
    "# ========= Part 4: ROC AUC計算 (振幅・面積特徴に限定) =========\n",
    "pairs = [(\"Normal\",\"Ischaemia\"),(\"Normal\",\"Congestion\"),(\"Ischaemia\",\"Congestion\")]\n",
    "\n",
    "# 評価対象の特徴量リスト\n",
    "features_to_eval = [\n",
    "    \"Amp_norm\", \"Pulse_Area_norm\", \"S_AUC_norm\", \"D_AUC_norm\", \"AUC_Ratio\"\n",
    "] \n",
    "\n",
    "# Red/IR Ratio 特徴量のリスト (修正後の列名を使用)\n",
    "ratio_features_to_eval = [\n",
    "    \"Red_IR_amp_norm_ratio\",\n",
    "    \"Pulse_Area_norm_ratio\", \"S_AUC_norm_ratio\", \"D_AUC_norm_ratio\"\n",
    "]\n",
    "\n",
    "# AUC Bootstrap Helper\n",
    "def bootstrap_auc_ci(y_true, y_score, n_bootstrap=200):\n",
    "    rng = np.random.default_rng(42)\n",
    "    aucs=[]\n",
    "    n=len(y_true)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.integers(0,n,n)\n",
    "        if len(np.unique(y_true[idx]))<2 or np.all(y_score[idx]==y_score[idx][0]): continue\n",
    "        aucs.append(roc_auc_score(y_true[idx],y_score[idx]))\n",
    "    if not aucs: return np.nan,np.nan,np.nan\n",
    "    return np.mean(aucs), np.percentile(aucs,2.5), np.percentile(aucs,97.5)\n",
    "\n",
    "\n",
    "rows=[]\n",
    "# Channel-specific features\n",
    "for ch in [\"Red\",\"IR\"]:\n",
    "    for depth in depths:\n",
    "        sub = df_feat[(df_feat.Channel==ch)&(df_feat.Depth==depth)]\n",
    "        if sub.empty: continue\n",
    "        for f in features_to_eval:\n",
    "            for c1,c2 in pairs:\n",
    "                d=sub[sub.State.isin([c1,c2])]\n",
    "                if d.empty: continue\n",
    "                y_true=(d.State==c1).astype(int).values\n",
    "                y_score=d[f].values\n",
    "                mask=~np.isnan(y_score)\n",
    "                y_true=y_true[mask]; y_score=y_score[mask]\n",
    "                \n",
    "                n_samples_used = len(y_true)\n",
    "                if n_samples_used < 5 or len(np.unique(y_true))<2: \n",
    "                    DEBUG_LOG(f\"[WARN] {ch} {depth}mm {c1} vs {c2} ({f}): Insufficient samples ({n_samples_used}) or classes.\")\n",
    "                    continue\n",
    "                \n",
    "                auc_bs,ci_lo,ci_hi=bootstrap_auc_ci(y_true,y_score)\n",
    "                rows.append({\"Channel\":ch,\"Depth\":depth,\"Feature\":f,\"Pair\":f\"{c1} vs {c2}\",\n",
    "                             \"AUC_bootstrap_mean\":auc_bs,\"CI_lower\":ci_lo,\"CI_upper\":ci_hi,\"n_samples\":n_samples_used})\n",
    "\n",
    "# Ratio features\n",
    "for depth in depths:\n",
    "    sub=df_ratio[df_ratio.Depth==depth]\n",
    "    if sub.empty: continue\n",
    "    for f in ratio_features_to_eval:\n",
    "        for c1,c2 in pairs:\n",
    "            d=sub[sub.State.isin([c1,c2])]\n",
    "            if d.empty: continue\n",
    "            y_true=(d.State==c1).astype(int).values\n",
    "            y_score=d[f].values\n",
    "            mask=~np.isnan(y_score)\n",
    "            y_true=y_true[mask]; y_score=y_score[mask]\n",
    "            \n",
    "            n_samples_used = len(y_true)\n",
    "            if n_samples_used < 5 or len(np.unique(y_true))<2: \n",
    "                DEBUG_LOG(f\"[WARN] Ratio {depth}mm {c1} vs {c2} ({f}): Insufficient samples ({n_samples_used}) or classes.\")\n",
    "                continue\n",
    "            \n",
    "            auc_bs,ci_lo,ci_hi=bootstrap_auc_ci(y_true,y_score)\n",
    "            rows.append({\"Channel\":\"Red/IR_Ratio\",\"Depth\":depth,\"Feature\":f,\"Pair\":f\"{c1} vs {c2}\",\n",
    "                         \"AUC_bootstrap_mean\":auc_bs,\"CI_lower\":ci_lo,\"CI_upper\":ci_hi,\"n_samples\":n_samples_used})\n",
    "\n",
    "\n",
    "df_auc_feat = pd.DataFrame(rows)\n",
    "df_auc_feat.to_csv(\"AUC_amplitude_area_features.csv\", index=False)\n",
    "DEBUG_LOG(\"--- Part 4 Complete: AUC calculation for Amplitude/Area Features saved. ---\")\n",
    "print(\"✅ Amplitude/Area features AUC analysis complete. Check AUC_amplitude_area_features.csv and log file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a14f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.signal import find_peaks, detrend, butter, filtfilt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import math\n",
    "from scipy.fft import rfftfreq, rfft \n",
    "\n",
    "# ========= 基本設定 =========\n",
    "fs = 2000  # Hz\n",
    "depths = [3, 9, 15, 21]\n",
    "state_map = {1: \"Normal\", 2: \"Ischaemia\", 3: \"Congestion\"}\n",
    "channels = {\"ppgA_Red_AGC\": \"Red\", \"ppgA_IR_AGC\": \"IR\"} \n",
    "DEBUG_MODE = True\n",
    "DEBUG_FILE = \"debug_log_part1_to_3_slope_features.txt\"\n",
    "with open(DEBUG_FILE, \"w\") as f:\n",
    "    f.write(\"--- Debug Log Start (Slope & Morphology Features) ---\\n\")\n",
    "\n",
    "def DEBUG_LOG(message):\n",
    "    if DEBUG_MODE:\n",
    "        with open(DEBUG_FILE, \"a\") as f:\n",
    "            f.write(message + \"\\n\")\n",
    "\n",
    "# --- BPF, BPM推定関数 (変更なし) ---\n",
    "def bandpass_filter(sig, fs, low=0.5, high=5.0, order=3):\n",
    "    nyq = fs / 2\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n",
    "    return filtfilt(b, a, sig)\n",
    "\n",
    "def estimate_bpm(signal, fs=2000):\n",
    "    sig = pd.Series(signal, dtype=float).interpolate().fillna(0).values\n",
    "    sig = detrend(sig)\n",
    "    sig = bandpass_filter(sig, fs)\n",
    "    prom = max(np.std(sig) * 0.3, np.ptp(sig) * 0.05)\n",
    "    peaks, _ = find_peaks(sig, prominence=prom, distance=int(fs * 0.5))\n",
    "    if len(peaks) < 2:\n",
    "        return np.nan\n",
    "    duration_sec = len(sig) / fs\n",
    "    bpm = len(peaks) / (duration_sec / 60.0)\n",
    "    return bpm\n",
    "\n",
    "# --- ★★★ 1拍ごとの特徴抽出 (勾配・形状特徴量計算を追加) ★★★\n",
    "def extract_pulse_features(signal, fs, dist=0.3):\n",
    "    threshold_height = np.min(signal) + (np.ptp(signal) * 0.1)\n",
    "    peaks, _ = find_peaks(signal, height=threshold_height, distance=int(fs * dist))\n",
    "    \n",
    "    feats = []\n",
    "    if len(peaks) < 2: return []\n",
    "        \n",
    "    for p in peaks:\n",
    "        left = max(0, p - int(0.5 * fs))\n",
    "        right = min(len(signal), p + int(0.5 * fs))\n",
    "        seg = signal[left:right]\n",
    "        if len(seg) < 5: continue\n",
    "        if np.any(np.isnan(seg)) or np.all(seg == seg[0]): continue\n",
    "        \n",
    "        peak_idx = np.argmax(seg)\n",
    "        trough_idx = np.argmin(seg[:peak_idx+1])\n",
    "        next_trough_idx = peak_idx + np.argmin(seg[peak_idx:])\n",
    "        \n",
    "        if trough_idx < peak_idx < next_trough_idx:\n",
    "            \n",
    "            # 共通の特徴\n",
    "            baseline = seg[trough_idx]\n",
    "            peak_val = seg[peak_idx]\n",
    "            amp = peak_val - baseline\n",
    "            rise_time_s = (peak_idx - trough_idx) / fs\n",
    "            fall_time_s = (next_trough_idx - peak_idx) / fs\n",
    "            \n",
    "            # --- 勾配特徴 ---\n",
    "            # Upslope: Amp / Rise Time\n",
    "            upslope = amp / (rise_time_s + 1e-6)\n",
    "            # Downslope: -Amp / Fall Time (負の値になるため絶対値または正の値で定義)\n",
    "            downslope = np.abs(amp / (fall_time_s + 1e-6))\n",
    "            \n",
    "            # --- 長さ特徴 (ユークリッド距離) ---\n",
    "            # 信号のサンプリング間隔 (dx)\n",
    "            dx = 1/fs\n",
    "            \n",
    "            # Upslope Length (UL): トラフからピークまでのユークリッド距離\n",
    "            rise_seg = seg[trough_idx:peak_idx+1]\n",
    "            dy_rise = np.diff(rise_seg)\n",
    "            ul = np.sum(np.sqrt(dy_rise**2 + dx**2))\n",
    "            \n",
    "            # Downslope Length (DL): ピークから次のトラフまでのユークリッド距離\n",
    "            fall_seg = seg[peak_idx:next_trough_idx+1]\n",
    "            dy_fall = np.diff(fall_seg)\n",
    "            dl = np.sum(np.sqrt(dy_fall**2 + dx**2))\n",
    "            \n",
    "            # --- Pulse Width (PW) ---\n",
    "            half = baseline + 0.5 * amp\n",
    "            seg_pw = seg[trough_idx:next_trough_idx+1]\n",
    "            above_half = np.where(seg_pw >= half)[0]\n",
    "            pw = (above_half[-1] - above_half[0]) / fs if len(above_half) > 1 else np.nan\n",
    "            \n",
    "            feats.append((amp, pw, rise_time_s, fall_time_s, upslope, downslope, ul, dl))\n",
    "    return feats\n",
    "\n",
    "# ========= Part 1 & 2: データロードと特徴抽出 =========\n",
    "records = []\n",
    "pulse_id_counter = 0 \n",
    "\n",
    "for depth in depths:\n",
    "    for i_state, state_name in state_map.items():\n",
    "        file_path = Path(f\"{depth}mm_AGC_data{i_state}.csv\")\n",
    "        DEBUG_LOG(f\"\\n--- Processing: {file_path.name} ({state_name}) ---\")\n",
    "\n",
    "        if not file_path.exists(): continue\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # --- BPM推定 ---\n",
    "        ir_sig = df.get(\"ppgA_IR_AGC\", pd.Series([]).values)\n",
    "        if len(ir_sig) == 0: continue\n",
    "            \n",
    "        bpm = estimate_bpm(ir_sig, fs)\n",
    "        window_sec = 60.0 / bpm if not np.isnan(bpm) and bpm > 0 else 1.0\n",
    "        window_sec = float(np.clip(window_sec, 0.6, 2.0))\n",
    "        \n",
    "        step = int(round(fs * window_sec))\n",
    "        current_pulse_id = pulse_id_counter \n",
    "\n",
    "        for col, ch_label in channels.items():\n",
    "            if col not in df.columns: continue\n",
    "            sig = df[col].values\n",
    "\n",
    "            # (1) Window-based Amplitude \n",
    "            n_win = len(sig) // step\n",
    "            DEBUG_LOG(f\"  Channel: {ch_label}, Total Windows: {n_win}\")\n",
    "            \n",
    "            for w in range(n_win):\n",
    "                s, e = w * step, (w + 1) * step\n",
    "                seg = sig[s:e]\n",
    "                if len(seg) < 5: continue\n",
    "                amp = seg.max() - seg.min()\n",
    "                \n",
    "                records.append({\n",
    "                    \"Depth\": depth, \"State\": state_name, \"Channel\": ch_label,\n",
    "                    \"Pulse_ID\": current_pulse_id,\n",
    "                    \"Amplitude\": amp, \"PulseWidth\": np.nan, \n",
    "                    \"Upslope\": np.nan, \"Downslope\": np.nan, \"UpslopeLength\": np.nan, \"DownslopeLength\": np.nan\n",
    "                })\n",
    "\n",
    "            # (2) peaksで詳細特徴抽出 (Peak-based)\n",
    "            # ★修正: 拡張した特徴量リストを受け取る★\n",
    "            feats = extract_pulse_features(sig, fs)\n",
    "            DEBUG_LOG(f\"  Channel: {ch_label}, Extracted Pulse Features: {len(feats)} pulses.\")\n",
    "            \n",
    "            for amp, pw, rt, ft, us, ds, ul, dl in feats:\n",
    "                records.append({\n",
    "                    \"Depth\": depth, \"State\": state_name, \"Channel\": ch_label,\n",
    "                    \"Pulse_ID\": current_pulse_id,\n",
    "                    \"Amplitude\": amp,\n",
    "                    \"PulseWidth\": pw,\n",
    "                    \"Upslope\": us, \n",
    "                    \"Downslope\": ds,\n",
    "                    \"UpslopeLength\": ul,\n",
    "                    \"DownslopeLength\": dl\n",
    "                })\n",
    "        \n",
    "        pulse_id_counter += 1 \n",
    "\n",
    "df_feat = pd.DataFrame(records)\n",
    "if df_feat.empty:\n",
    "    raise RuntimeError(\"Error: No data loaded. Please check CSV files.\")\n",
    "DEBUG_LOG(f\"\\n--- Part 2 Complete: Total Feature Rows: {len(df_feat)} ---\")\n",
    "\n",
    "\n",
    "# ========= Part 3: 複合指標と正規化 (勾配・形状特徴に特化) =========\n",
    "\n",
    "# --- 正規化（Redは3mm Red Normal基準、IRは3mm IR Normal基準） ---\n",
    "def normalize_channel_amp(df, ch):\n",
    "    base_data = df.query(\"Channel==@ch and Depth==3 and State=='Normal'\")[\"Amplitude\"]\n",
    "    base = base_data.mean()\n",
    "    DEBUG_LOG(f\"Normalization Base (Amplitude, {ch}): Mean={base:.4e}, Count={len(base_data)}\")\n",
    "    \n",
    "    if pd.isna(base) or base == 0:\n",
    "        df.loc[df.Channel == ch, \"Amp_norm\"] = np.nan\n",
    "    else:\n",
    "        df.loc[df.Channel == ch, \"Amp_norm\"] = df.loc[df.Channel == ch, \"Amplitude\"] / base\n",
    "\n",
    "normalize_channel_amp(df_feat, \"Red\")\n",
    "normalize_channel_amp(df_feat, \"IR\")\n",
    "\n",
    "# ★★★ 勾配・形状の特徴量計算 ★★★\n",
    "# Amplitude_normを基準に正規化が必要な特徴量の列名\n",
    "features_for_norm = [\"Upslope\", \"Downslope\", \"UpslopeLength\", \"DownslopeLength\"]\n",
    "\n",
    "for f in features_for_norm:\n",
    "    # 勾配（Upslope, Downslope）や長さ（UL, DL）は振幅に依存するため、Amp_normで正規化\n",
    "    df_feat[f\"{f}_norm\"] = df_feat[f] / (df_feat[\"Amp_norm\"] + 1e-6)\n",
    "\n",
    "# ★★★ 複合特徴量 ★★★\n",
    "df_feat[\"Slope_Ratio\"] = df_feat[\"Upslope_norm\"] / (df_feat[\"Downslope_norm\"] + 1e-6) # US_norm / DS_norm\n",
    "df_feat[\"Length_Height_Ratio\"] = df_feat[\"PulseWidth\"] / (df_feat[\"Amplitude\"] + 1e-6) # Width / Amp\n",
    "df_feat[\"SlopeLength_Ratio\"] = df_feat[\"UpslopeLength_norm\"] / (df_feat[\"DownslopeLength_norm\"] + 1e-6) # UL_norm / DL_norm\n",
    "\n",
    "DEBUG_LOG(f\"\\n--- Part 3 Complete: Normalized Slope Features Created ---\")\n",
    "\n",
    "# --- Red/IR比 (マージロジック) ---\n",
    "amp_data = df_feat.dropna(subset=['Amplitude', 'Amp_norm']).copy()\n",
    "\n",
    "merge_cols = ['Depth', 'State', 'Pulse_ID'] + features_for_norm + [f\"{f}_norm\" for f in features_for_norm] + [\"Amplitude\", \"Amp_norm\", \"PulseWidth\"]\n",
    "\n",
    "df_red = amp_data[amp_data.Channel == \"Red\"][merge_cols].rename(columns={\"Amplitude\": \"Amplitude_Red\", \"Amp_norm\": \"Amp_norm_Red\"})\n",
    "df_ir = amp_data[amp_data.Channel == \"IR\"][merge_cols].rename(columns={\"Amplitude\": \"Amplitude_IR\", \"Amp_norm\": \"Amp_norm_IR\"})\n",
    "\n",
    "df_ratio = pd.merge(df_red, df_ir, on=['Depth','State','Pulse_ID'], how='inner', suffixes=('_Red', '_IR'))\n",
    "DEBUG_LOG(f\"Ratio Data Rows (Merged for Slope Features): {len(df_ratio)}\")\n",
    "\n",
    "# Red/IR Ratio 勾配・長さの特徴量の計算\n",
    "# Slope/Length の Red/IR 比率（例: Red_Upslope_norm / IR_Upslope_norm）\n",
    "for f in features_for_norm:\n",
    "    df_ratio[f\"{f}_norm_ratio\"] = df_ratio[f\"{f}_norm_Red\"] / (df_ratio[f\"{f}_norm_IR\"] + 1e-6)\n",
    "\n",
    "# Amplitude Ratioは評価対象外のため省略\n",
    "\n",
    "# ========= Part 4: ROC AUC計算 (勾配・形状特徴に限定) =========\n",
    "pairs = [(\"Normal\",\"Ischaemia\"),(\"Normal\",\"Congestion\"),(\"Ischaemia\",\"Congestion\")]\n",
    "\n",
    "# ★★★ 評価対象の特徴量リストを更新 ★★★\n",
    "features_to_eval = [\n",
    "    \"Upslope_norm\", \"Downslope_norm\", \"UpslopeLength_norm\", \"DownslopeLength_norm\", \n",
    "    \"Slope_Ratio\", \"Length_Height_Ratio\", \"SlopeLength_Ratio\"\n",
    "] \n",
    "\n",
    "# Red/IR Ratio 勾配・長さの特徴量のリスト\n",
    "ratio_features_to_eval = [\n",
    "    f\"{f}_norm_ratio\" for f in features_for_norm\n",
    "]\n",
    "\n",
    "# AUC Bootstrap Helper (再定義は省略)\n",
    "def bootstrap_auc_ci(y_true, y_score, n_bootstrap=200):\n",
    "    rng = np.random.default_rng(42)\n",
    "    aucs=[]\n",
    "    n=len(y_true)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.integers(0,n,n)\n",
    "        if len(np.unique(y_true[idx]))<2 or np.all(y_score[idx]==y_score[idx][0]): continue\n",
    "        aucs.append(roc_auc_score(y_true[idx],y_score[idx]))\n",
    "    if not aucs: return np.nan,np.nan,np.nan\n",
    "    return np.mean(aucs), np.percentile(aucs,2.5), np.percentile(aucs,97.5)\n",
    "\n",
    "\n",
    "rows=[]\n",
    "# Channel-specific features\n",
    "for ch in [\"Red\",\"IR\"]:\n",
    "    for depth in depths:\n",
    "        sub = df_feat[(df_feat.Channel==ch)&(df_feat.Depth==depth)]\n",
    "        if sub.empty: continue\n",
    "        for f in features_to_eval:\n",
    "            for c1,c2 in pairs:\n",
    "                d=sub[sub.State.isin([c1,c2])]\n",
    "                if d.empty: continue\n",
    "                y_true=(d.State==c1).astype(int).values\n",
    "                y_score=d[f].values\n",
    "                mask=~np.isnan(y_score)\n",
    "                y_true=y_true[mask]; y_score=y_score[mask]\n",
    "                \n",
    "                n_samples_used = len(y_true)\n",
    "                if n_samples_used < 5 or len(np.unique(y_true))<2: \n",
    "                    DEBUG_LOG(f\"[WARN] {ch} {depth}mm {c1} vs {c2} ({f}): Insufficient samples ({n_samples_used}) or classes.\")\n",
    "                    continue\n",
    "                \n",
    "                auc_bs,ci_lo,ci_hi=bootstrap_auc_ci(y_true,y_score)\n",
    "                rows.append({\"Channel\":ch,\"Depth\":depth,\"Feature\":f,\"Pair\":f\"{c1} vs {c2}\",\n",
    "                             \"AUC_bootstrap_mean\":auc_bs,\"CI_lower\":ci_lo,\"CI_upper\":ci_hi,\"n_samples\":n_samples_used})\n",
    "\n",
    "# Ratio features\n",
    "for depth in depths:\n",
    "    sub=df_ratio[df_ratio.Depth==depth]\n",
    "    if sub.empty: continue\n",
    "    for f in ratio_features_to_eval:\n",
    "        for c1,c2 in pairs:\n",
    "            d=sub[sub.State.isin([c1,c2])]\n",
    "            if d.empty: continue\n",
    "            y_true=(d.State==c1).astype(int).values\n",
    "            y_score=d[f].values\n",
    "            mask=~np.isnan(y_score)\n",
    "            y_true=y_true[mask]; y_score=y_score[mask]\n",
    "            \n",
    "            n_samples_used = len(y_true)\n",
    "            if n_samples_used < 5 or len(np.unique(y_true))<2: \n",
    "                DEBUG_LOG(f\"[WARN] Ratio {depth}mm {c1} vs {c2} ({f}): Insufficient samples ({n_samples_used}) or classes.\")\n",
    "                continue\n",
    "            \n",
    "            auc_bs,ci_lo,ci_hi=bootstrap_auc_ci(y_true,y_score)\n",
    "            rows.append({\"Channel\":\"Red/IR_Ratio\",\"Depth\":depth,\"Feature\":f,\"Pair\":f\"{c1} vs {c2}\",\n",
    "                         \"AUC_bootstrap_mean\":auc_bs,\"CI_lower\":ci_lo,\"CI_upper\":ci_hi,\"n_samples\":n_samples_used})\n",
    "\n",
    "\n",
    "df_auc_feat = pd.DataFrame(rows)\n",
    "df_auc_feat.to_csv(\"AUC_slope_morphology_features.csv\", index=False)\n",
    "DEBUG_LOG(\"--- Part 4 Complete: AUC calculation for Slope/Morphology Features saved. ---\")\n",
    "print(\"✅ Slope/Morphology features AUC analysis complete. Check AUC_slope_morphology_features.csv and log file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd09c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.signal import find_peaks, detrend, butter, filtfilt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from scipy.stats import skew, kurtosis \n",
    "import math\n",
    "from scipy.fft import rfftfreq, rfft \n",
    "\n",
    "# ========= 基本設定 =========\n",
    "fs = 2000  # Hz\n",
    "depths = [3, 9, 15, 21]\n",
    "state_map = {1: \"Normal\", 2: \"Ischaemia\", 3: \"Congestion\"}\n",
    "channels = {\"ppgA_Red_AGC\": \"Red\", \"ppgA_IR_AGC\": \"IR\"} \n",
    "DEBUG_MODE = True\n",
    "DEBUG_FILE = \"debug_log_part1_to_3_composite_noise_features.txt\"\n",
    "with open(DEBUG_FILE, \"w\") as f:\n",
    "    f.write(\"--- Debug Log Start (Composite & Noise Features) ---\\n\")\n",
    "\n",
    "def DEBUG_LOG(message):\n",
    "    if DEBUG_MODE:\n",
    "        with open(DEBUG_FILE, \"a\") as f:\n",
    "            f.write(message + \"\\n\")\n",
    "\n",
    "# --- BPF, BPM推定関数 (変更なし) ---\n",
    "def bandpass_filter(sig, fs, low=0.5, high=5.0, order=3):\n",
    "    nyq = fs / 2\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n",
    "    return filtfilt(b, a, sig)\n",
    "\n",
    "def estimate_bpm(signal, fs=2000):\n",
    "    sig = pd.Series(signal, dtype=float).interpolate().fillna(0).values\n",
    "    sig = detrend(sig)\n",
    "    sig = bandpass_filter(sig, fs)\n",
    "    prom = max(np.std(sig) * 0.3, np.ptp(sig) * 0.05)\n",
    "    peaks, _ = find_peaks(sig, prominence=prom, distance=int(fs * 0.5))\n",
    "    if len(peaks) < 2:\n",
    "        return np.nan\n",
    "    duration_sec = len(sig) / fs\n",
    "    bpm = len(peaks) / (duration_sec / 60.0)\n",
    "    return bpm\n",
    "\n",
    "# --- ★★★ 1拍ごとの特徴抽出 (歪度・尖度・Width Ratioの準備) ★★★\n",
    "def extract_pulse_features(signal, fs, dist=0.3):\n",
    "    threshold_height = np.min(signal) + (np.ptp(signal) * 0.1)\n",
    "    peaks, _ = find_peaks(signal, height=threshold_height, distance=int(fs * dist))\n",
    "    \n",
    "    feats = []\n",
    "    if len(peaks) < 2: return []\n",
    "        \n",
    "    for p in peaks:\n",
    "        left = max(0, p - int(0.5 * fs))\n",
    "        right = min(len(signal), p + int(0.5 * fs))\n",
    "        seg = signal[left:right]\n",
    "        if len(seg) < 5: continue\n",
    "        if np.any(np.isnan(seg)) or np.all(seg == seg[0]): continue\n",
    "        \n",
    "        peak_idx = np.argmax(seg)\n",
    "        trough_idx = np.argmin(seg[:peak_idx+1])\n",
    "        next_trough_idx = peak_idx + np.argmin(seg[peak_idx:])\n",
    "        \n",
    "        if trough_idx < peak_idx < next_trough_idx:\n",
    "            \n",
    "            baseline = seg[trough_idx]\n",
    "            amp = seg[peak_idx] - baseline\n",
    "            \n",
    "            # --- 複合・ノイズ特徴 (1拍セグメントベース) ---\n",
    "            pulse_seg = seg[trough_idx:next_trough_idx+1] - baseline # 基線補正\n",
    "            \n",
    "            # 1. Skewness (歪度)\n",
    "            seg_skew = skew(pulse_seg)\n",
    "            \n",
    "            # 2. Kurtosis (尖度)\n",
    "            seg_kurtosis = kurtosis(pulse_seg)\n",
    "            \n",
    "            # 3. Pulse Width (PW) - Width Ratioの準備\n",
    "            half = baseline + 0.5 * amp\n",
    "            seg_pw_full = seg[trough_idx:next_trough_idx+1]\n",
    "            above_half = np.where(seg_pw_full >= half)[0]\n",
    "            # 拍周期\n",
    "            period_s = (next_trough_idx - trough_idx) / fs\n",
    "            # パルス幅\n",
    "            pw_s = (above_half[-1] - above_half[0]) / fs if len(above_half) > 1 else np.nan\n",
    "            \n",
    "            # 4. Datum Area (基線からの総面積) - Area特徴と重複するため、ここではPulse Areaとして計算\n",
    "            area_datum = np.trapz(pulse_seg, dx=1/fs) \n",
    "            \n",
    "            feats.append((amp, seg_skew, seg_kurtosis, pw_s, period_s, area_datum))\n",
    "    return feats\n",
    "\n",
    "# --- 信号全体の特徴量計算 (SNR, ZCR) ---\n",
    "def calculate_global_features(sig, fs):\n",
    "    # 1. SNR (Signal-to-Noise Ratio)\n",
    "    # PPGではDC成分(トレンド)を信号と見なし、残りの高周波成分をノイズと見なす方法が一般的\n",
    "    \n",
    "    # 信号成分 (低周波成分) - BPFを通すことでノイズと分離\n",
    "    signal_component = bandpass_filter(sig, fs)\n",
    "    \n",
    "    # ノイズ成分 (信号からBPF成分を引いたもの) - 高周波ノイズ＋DCトレンド\n",
    "    # DCトレンドを除去するためにdetrend済み信号を使用\n",
    "    detrended_sig = detrend(sig)\n",
    "    noise_component = detrended_sig - signal_component\n",
    "\n",
    "    # SNR in dB\n",
    "    power_signal = np.mean(signal_component**2)\n",
    "    power_noise = np.mean(noise_component**2)\n",
    "    \n",
    "    if power_noise > 0:\n",
    "        snr_db = 10 * np.log10(power_signal / power_noise)\n",
    "    else:\n",
    "        snr_db = np.nan\n",
    "        \n",
    "    # 2. ZCR (Zero-Crossing Rate) - 信号の周波数・ノイズレベルの指標\n",
    "    # Detrended (平均ゼロ付近)の信号を使用\n",
    "    zcr = np.sum(np.diff(np.sign(detrended_sig)) != 0) / len(detrended_sig)\n",
    "    \n",
    "    return snr_db, zcr\n",
    "\n",
    "\n",
    "# ========= Part 1 & 2: データロードと特徴抽出 =========\n",
    "records = []\n",
    "global_records = []\n",
    "pulse_id_counter = 0 \n",
    "\n",
    "for depth in depths:\n",
    "    for i_state, state_name in state_map.items():\n",
    "        file_path = Path(f\"{depth}mm_AGC_data{i_state}.csv\")\n",
    "        DEBUG_LOG(f\"\\n--- Processing: {file_path.name} ({state_name}) ---\")\n",
    "\n",
    "        if not file_path.exists(): continue\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # --- BPM推定 ---\n",
    "        ir_sig = df.get(\"ppgA_IR_AGC\", pd.Series([]).values)\n",
    "        if len(ir_sig) == 0: continue\n",
    "            \n",
    "        bpm = estimate_bpm(ir_sig, fs)\n",
    "        window_sec = 60.0 / bpm if not np.isnan(bpm) and bpm > 0 else 1.0\n",
    "        window_sec = float(np.clip(window_sec, 0.6, 2.0))\n",
    "        \n",
    "        step = int(round(fs * window_sec))\n",
    "        current_pulse_id = pulse_id_counter \n",
    "\n",
    "        for col, ch_label in channels.items():\n",
    "            if col not in df.columns: continue\n",
    "            sig = df[col].values\n",
    "\n",
    "            # --- (A) 全体特徴量 (SNR, ZCR) の計算と記録 ---\n",
    "            snr, zcr = calculate_global_features(sig, fs)\n",
    "            global_records.append({\n",
    "                \"Depth\": depth, \"State\": state_name, \"Channel\": ch_label,\n",
    "                \"Pulse_ID\": current_pulse_id, # このIDでマージする\n",
    "                \"SNR\": snr, \"ZCR\": zcr\n",
    "            })\n",
    "            DEBUG_LOG(f\"  Channel: {ch_label}, SNR: {snr:.2f} dB, ZCR: {zcr:.4f}\")\n",
    "\n",
    "            # --- (B) 1拍ベースの特徴抽出 (歪度, 尖度, 幅, 面積) ---\n",
    "            feats = extract_pulse_features(sig, fs)\n",
    "            DEBUG_LOG(f\"  Channel: {ch_label}, Extracted Pulse Features: {len(feats)} pulses.\")\n",
    "            \n",
    "            for amp, seg_skew, seg_kurtosis, pw_s, period_s, area_datum in feats:\n",
    "                records.append({\n",
    "                    \"Depth\": depth, \"State\": state_name, \"Channel\": ch_label,\n",
    "                    \"Pulse_ID\": current_pulse_id, # Global特徴量と結合するためのID\n",
    "                    \"Amplitude\": amp,\n",
    "                    \"Skewness\": seg_skew,\n",
    "                    \"Kurtosis\": seg_kurtosis,\n",
    "                    \"PulseWidth\": pw_s,\n",
    "                    \"PulsePeriod\": period_s,\n",
    "                    \"DatumArea\": area_datum,\n",
    "                })\n",
    "        \n",
    "        pulse_id_counter += 1 \n",
    "\n",
    "df_feat_pulse = pd.DataFrame(records)\n",
    "df_feat_global = pd.DataFrame(global_records)\n",
    "if df_feat_pulse.empty or df_feat_global.empty:\n",
    "    raise RuntimeError(\"Error: No data loaded. Please check CSV files.\")\n",
    "\n",
    "# Global特徴量をPulse特徴量に結合\n",
    "df_feat = pd.merge(df_feat_pulse, df_feat_global, on=['Depth','State','Channel','Pulse_ID'], how='left')\n",
    "\n",
    "DEBUG_LOG(f\"\\n--- Part 2 Complete: Total Feature Rows: {len(df_feat)} ---\")\n",
    "\n",
    "\n",
    "# ========= Part 3: 複合指標と正規化 (複合・ノイズ特徴に特化) =========\n",
    "\n",
    "# --- 複合特徴量 (比率) ---\n",
    "# Width Ratio: Pulse Width / Pulse Period\n",
    "df_feat[\"Width_Ratio\"] = df_feat[\"PulseWidth\"] / (df_feat[\"PulsePeriod\"] + 1e-6)\n",
    "\n",
    "# Amplitudeの正規化\n",
    "def normalize_channel_amp(df, ch):\n",
    "    base_data = df.query(\"Channel==@ch and Depth==3 and State=='Normal'\")[\"Amplitude\"]\n",
    "    base = base_data.mean()\n",
    "    DEBUG_LOG(f\"Normalization Base (Amplitude, {ch}): Mean={base:.4e}, Count={len(base_data)}\")\n",
    "    \n",
    "    if pd.isna(base) or base == 0:\n",
    "        df.loc[df.Channel == ch, \"Amp_norm\"] = np.nan\n",
    "    else:\n",
    "        df.loc[df.Channel == ch, \"Amp_norm\"] = df.loc[df.Channel == ch, \"Amplitude\"] / base\n",
    "\n",
    "normalize_channel_amp(df_feat, \"Red\")\n",
    "normalize_channel_amp(df_feat, \"IR\")\n",
    "\n",
    "# Datum AreaをAmp_normで正規化 (面積は振幅に依存するため)\n",
    "df_feat[\"DatumArea_norm\"] = df_feat[\"DatumArea\"] / (df_feat[\"Amp_norm\"] + 1e-6)\n",
    "\n",
    "DEBUG_LOG(f\"\\n--- Part 3 Complete: Composite Features Created ---\")\n",
    "\n",
    "\n",
    "# --- Red/IR比 (マージロジック) ---\n",
    "# 歪度、尖度、Width Ratio、SNR、ZCRは比率にしない（または意味がない）\n",
    "# Datum Area_norm の Red/IR 比を計算する\n",
    "\n",
    "amp_data = df_feat.dropna(subset=['Amplitude', 'Amp_norm']).copy()\n",
    "\n",
    "# 比率計算の対象となる特徴量（正規化済みDatum Area）\n",
    "area_features = [\"DatumArea\"] \n",
    "# Width Ratioは、RedとIRで脈拍周期が等しいと仮定すると、Pulse Widthの比率と等価\n",
    "\n",
    "merge_cols = ['Depth', 'State', 'Pulse_ID', 'DatumArea_norm']\n",
    "\n",
    "df_red = amp_data[amp_data.Channel == \"Red\"][merge_cols].rename(\n",
    "    columns={\"DatumArea_norm\": \"DatumArea_norm_Red\"}\n",
    ")\n",
    "df_ir = amp_data[amp_data.Channel == \"IR\"][merge_cols].rename(\n",
    "    columns={\"DatumArea_norm\": \"DatumArea_norm_IR\"}\n",
    ")\n",
    "\n",
    "df_ratio = pd.merge(df_red, df_ir, on=['Depth','State','Pulse_ID'], how='inner')\n",
    "DEBUG_LOG(f\"Ratio Data Rows (Merged for Datum Area Ratio): {len(df_ratio)}\")\n",
    "\n",
    "# Datum Area Ratio の計算\n",
    "df_ratio[\"DatumArea_norm_ratio\"] = df_ratio[\"DatumArea_norm_Red\"] / (df_ratio[\"DatumArea_norm_IR\"] + 1e-6)\n",
    "\n",
    "\n",
    "# ========= Part 4: ROC AUC計算 (複合・ノイズ特徴に限定) =========\n",
    "pairs = [(\"Normal\",\"Ischaemia\"),(\"Normal\",\"Congestion\"),(\"Ischaemia\",\"Congestion\")]\n",
    "\n",
    "# ★★★ 評価対象の特徴量リストを更新 ★★★\n",
    "# Skewness, Kurtosis, Width_Ratio, SNR, ZCR は単一チャンネル特徴量\n",
    "features_to_eval = [\n",
    "    \"Skewness\", \"Kurtosis\", \"Width_Ratio\", \"SNR\", \"ZCR\", \"DatumArea_norm\"\n",
    "] \n",
    "\n",
    "# Red/IR Ratio 特徴量のリスト\n",
    "ratio_features_to_eval = [\n",
    "    \"DatumArea_norm_ratio\"\n",
    "]\n",
    "\n",
    "# AUC Bootstrap Helper\n",
    "def bootstrap_auc_ci(y_true, y_score, n_bootstrap=200):\n",
    "    rng = np.random.default_rng(42)\n",
    "    aucs=[]\n",
    "    n=len(y_true)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.integers(0,n,n)\n",
    "        if len(np.unique(y_true[idx]))<2 or np.all(y_score[idx]==y_score[idx][0]): continue\n",
    "        aucs.append(roc_auc_score(y_true[idx],y_score[idx]))\n",
    "    if not aucs: return np.nan,np.nan,np.nan\n",
    "    return np.mean(aucs), np.percentile(aucs,2.5), np.percentile(aucs,97.5)\n",
    "\n",
    "\n",
    "rows=[]\n",
    "# Channel-specific features\n",
    "for ch in [\"Red\",\"IR\"]:\n",
    "    for depth in depths:\n",
    "        sub = df_feat[(df_feat.Channel==ch)&(df_feat.Depth==depth)]\n",
    "        if sub.empty: continue\n",
    "        for f in features_to_eval:\n",
    "            for c1,c2 in pairs:\n",
    "                # SNR, ZCRはPulse_ID単位でユニークなため、重複を削除してから評価する\n",
    "                if f in [\"SNR\", \"ZCR\"]:\n",
    "                    d = sub[sub.State.isin([c1,c2])].drop_duplicates(subset=[\"Pulse_ID\"])\n",
    "                else:\n",
    "                    d = sub[sub.State.isin([c1,c2])]\n",
    "                    \n",
    "                if d.empty: continue\n",
    "                \n",
    "                y_true=(d.State==c1).astype(int).values\n",
    "                y_score=d[f].values\n",
    "                mask=~np.isnan(y_score)\n",
    "                y_true=y_true[mask]; y_score=y_score[mask]\n",
    "                \n",
    "                n_samples_used = len(y_true)\n",
    "                if n_samples_used < 5 or len(np.unique(y_true))<2: \n",
    "                    DEBUG_LOG(f\"[WARN] {ch} {depth}mm {c1} vs {c2} ({f}): Insufficient samples ({n_samples_used}) or classes.\")\n",
    "                    continue\n",
    "                \n",
    "                auc_bs,ci_lo,ci_hi=bootstrap_auc_ci(y_true,y_score)\n",
    "                rows.append({\"Channel\":ch,\"Depth\":depth,\"Feature\":f,\"Pair\":f\"{c1} vs {c2}\",\n",
    "                             \"AUC_bootstrap_mean\":auc_bs,\"CI_lower\":ci_lo,\"CI_upper\":ci_hi,\"n_samples\":n_samples_used})\n",
    "\n",
    "# Ratio features\n",
    "for depth in depths:\n",
    "    sub=df_ratio[df_ratio.Depth==depth]\n",
    "    if sub.empty: continue\n",
    "    for f in ratio_features_to_eval:\n",
    "        for c1,c2 in pairs:\n",
    "            d=sub[sub.State.isin([c1,c2])]\n",
    "            if d.empty: continue\n",
    "            y_true=(d.State==c1).astype(int).values\n",
    "            y_score=d[f].values\n",
    "            mask=~np.isnan(y_score)\n",
    "            y_true=y_true[mask]; y_score=y_score[mask]\n",
    "            \n",
    "            n_samples_used = len(y_true)\n",
    "            if n_samples_used < 5 or len(np.unique(y_true))<2: \n",
    "                DEBUG_LOG(f\"[WARN] Ratio {depth}mm {c1} vs {c2} ({f}): Insufficient samples ({n_samples_used}) or classes.\")\n",
    "                continue\n",
    "            \n",
    "            auc_bs,ci_lo,ci_hi=bootstrap_auc_ci(y_true,y_score)\n",
    "            rows.append({\"Channel\":\"Red/IR_Ratio\",\"Depth\":depth,\"Feature\":f,\"Pair\":f\"{c1} vs {c2}\",\n",
    "                         \"AUC_bootstrap_mean\":auc_bs,\"CI_lower\":ci_lo,\"CI_upper\":ci_hi,\"n_samples\":n_samples_used})\n",
    "\n",
    "\n",
    "df_auc_feat = pd.DataFrame(rows)\n",
    "df_auc_feat.to_csv(\"AUC_composite_noise_features.csv\", index=False)\n",
    "DEBUG_LOG(\"--- Part 4 Complete: AUC calculation for Composite/Noise Features saved. ---\")\n",
    "print(\"✅ Composite/Noise features AUC analysis complete. Check AUC_composite_noise_features.csv and log file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# ========= 1. データ読み込みと準備 =========\n",
    "\n",
    "# 最終的に生成されたAUCサマリーファイル名を指定（必要に応じて変更してください）\n",
    "FILE_PATH = \"AUC_all.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {FILE_PATH}. Please run the previous code block to generate the CSV.\")\n",
    "    exit()\n",
    "\n",
    "# NaN値を含む行を削除し、AUC値が0.7未満のものは無視する\n",
    "df_filtered = df.dropna(subset=['AUC_bootstrap_mean'])\n",
    "df_filtered_plot = df_filtered[df_filtered['AUC_bootstrap_mean'] > 0.7].copy() # プロット対象（AUC>0.7）のみ\n",
    "\n",
    "# ========= 2. 特徴量の整形と色の定義 =========\n",
    "\n",
    "# 2.1. 特徴名のマッピングと結合\n",
    "def format_feature_name(row):\n",
    "    feature = row['Feature']\n",
    "    channel = row['Channel']\n",
    "    \n",
    "    # Amp_normをAmplitudeに改名\n",
    "    if feature == 'Amp_norm':\n",
    "        feature = 'Amplitude'\n",
    "        \n",
    "    # Pulse_Area_normはPulse_Areaと同一とみなし削除（Noneを返すことでフィルタリング）\n",
    "    if feature == 'Pulse_Area_norm':\n",
    "        return None\n",
    "        \n",
    "    # ChannelとFeatureを結合 \n",
    "    if channel in ['Red', 'IR']:\n",
    "        return f\"{channel}_{feature}\"\n",
    "    elif channel == 'Red/IR_Ratio':\n",
    "        # Ratioの場合はFeature名をそのまま使用（例: Red_IR_amp_norm_ratio）\n",
    "        return feature\n",
    "    return None\n",
    "\n",
    "df_filtered_plot['Combined_Feature'] = df_filtered_plot.apply(format_feature_name, axis=1)\n",
    "df_filtered_plot = df_filtered_plot.dropna(subset=['Combined_Feature'])\n",
    "\n",
    "# 2.2. 色の定義\n",
    "def get_feature_color(feature_name):\n",
    "    \"\"\"Red/IRに基づいて色を決定\"\"\"\n",
    "    feature_name = feature_name.lower()\n",
    "    if 'red' in feature_name:\n",
    "        return 'red'\n",
    "    elif 'ir' in feature_name:\n",
    "        return 'purple'\n",
    "    return 'black'\n",
    "\n",
    "# 2.3. ヒートマップ描画用データフレームの準備\n",
    "pair_order = [\n",
    "    'Normal vs Ischaemia',\n",
    "    'Normal vs Congestion',\n",
    "    'Ischaemia vs Congestion'\n",
    "]\n",
    "depth_order = sorted(df_filtered_plot['Depth'].unique())\n",
    "\n",
    "text_grid = {} # key: (Pair, Depth), value: [(text, color, auc_value), ...]\n",
    "heatmap_values = pd.DataFrame(index=pair_order, columns=depth_order, dtype=float)\n",
    "\n",
    "for index, row in df_filtered_plot.iterrows():\n",
    "    pair = row['Pair']\n",
    "    depth = row['Depth']\n",
    "    feature_name = row['Combined_Feature']\n",
    "    auc_value = row['AUC_bootstrap_mean']\n",
    "    \n",
    "    key = (pair, depth)\n",
    "    \n",
    "    # テキスト準備\n",
    "    text = f\"{feature_name}: {auc_value:.2f}\"\n",
    "    color = get_feature_color(feature_name)\n",
    "    \n",
    "    if key not in text_grid:\n",
    "        text_grid[key] = []\n",
    "    # (text, color, auc_value) のタプルでAUC値も格納\n",
    "    text_grid[key].append((text, color, auc_value))\n",
    "    \n",
    "    # 背景色の基準（セル内の最大AUC）を更新\n",
    "    if pair in pair_order and depth in depth_order:\n",
    "        current_max = heatmap_values.loc[pair, depth]\n",
    "        if pd.isna(current_max) or auc_value > current_max:\n",
    "            heatmap_values.loc[pair, depth] = auc_value\n",
    "\n",
    "\n",
    "# AUCが0.7未満（プロット対象外）のセルは、カラーマップの最小値（0.5）で埋める\n",
    "MIN_AUC_FOR_CMAP = 0.5 \n",
    "heatmap_values = heatmap_values.fillna(MIN_AUC_FOR_CMAP) \n",
    "\n",
    "# ========= 3. ヒートマップのプロット =========\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 4)) \n",
    "\n",
    "# 3.1. 背景色\n",
    "cmap = plt.cm.get_cmap('YlGnBu_r') \n",
    "norm = mcolors.Normalize(vmin=MIN_AUC_FOR_CMAP, vmax=1.0) \n",
    "\n",
    "cax = ax.imshow(heatmap_values.values, cmap=cmap, norm=norm, aspect='auto', interpolation='nearest')\n",
    "\n",
    "# 3.2. 軸の設定\n",
    "ax.set_xticks(np.arange(len(depth_order)))\n",
    "ax.set_yticks(np.arange(len(pair_order)))\n",
    "ax.set_xticklabels([f'{d} mm' for d in depth_order])\n",
    "ax.set_yticklabels(pair_order)\n",
    "\n",
    "ax.set_xlabel('Depth (mm)', fontsize=13)\n",
    "ax.set_ylabel('Pairwise Comparison', fontsize=13)\n",
    "ax.set_title(f'High AUC Features (Top 5)', fontsize=16, pad=20)\n",
    "\n",
    "# 3.3. テキストの描画\n",
    "for i, pair in enumerate(pair_order):\n",
    "    for j, depth in enumerate(depth_order):\n",
    "        key = (pair, depth)\n",
    "        \n",
    "        # AUC > 0.7のデータがあるセルのみにテキストを描画\n",
    "        if key in text_grid and heatmap_values.loc[pair, depth] > 0.7:\n",
    "            \n",
    "            # ★★★ 修正箇所: AUCで降順ソートし、上位5つに制限 ★★★\n",
    "            # text_grid[key] は [(text, color, auc_value), ...]\n",
    "            sorted_entries = sorted(text_grid[key], key=lambda x: x[2], reverse=True)\n",
    "            \n",
    "            # 上位5つの (text, color) のみを取得\n",
    "            top_5_entries = [(t, c) for t, c, a in sorted_entries[:5]] \n",
    "            \n",
    "            n_entries = len(top_5_entries)\n",
    "            \n",
    "            # 垂直方向の中心から上下にずらして配置を調整\n",
    "            # 5行まで対応するようにオフセットを調整\n",
    "            y_offsets = np.linspace(-0.35, 0.35, n_entries) if n_entries > 0 else []\n",
    "            \n",
    "            for k, (text, color) in enumerate(top_5_entries):\n",
    "                ax.text(j, i + y_offsets[k],\n",
    "                        text, \n",
    "                        ha=\"center\", \n",
    "                        va=\"center\", \n",
    "                        color=color, \n",
    "                        fontsize=8, \n",
    "                        linespacing=1.2)\n",
    "\n",
    "# 3.4. カラーバーの追加と修正\n",
    "cbar_ticks = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "cbar = fig.colorbar(cax, ticks=cbar_ticks, label='AUC Value')\n",
    "\n",
    "custom_labels = [f'{t:.1f}' for t in cbar_ticks]\n",
    "custom_labels[0] = f'≤ {MIN_AUC_FOR_CMAP:.1f}'\n",
    "\n",
    "cbar.ax.set_yticklabels(custom_labels) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. ファイルパスのリストを定義\n",
    "file_paths = [\n",
    "    \"AUC_time_features_bpm_norm.csv\",\n",
    "    \"AUC_amplitude_area_features.csv\",\n",
    "    \"AUC_slope_morphology_features.csv\",\n",
    "    \"AUC_composite_noise_features.csv\"\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# 2. 各CSVファイルを読み込み、リストに追加\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        all_data.append(df)\n",
    "        print(f\"✅ Loaded: {file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        # ファイルが見つからない場合は警告を表示してスキップ\n",
    "        print(f\"❌ Warning: File not found: {file_path}. Skipping this file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error reading {file_path}: {e}. Skipping this file.\")\n",
    "        \n",
    "# 3. 全てのDataFrameを結合\n",
    "if not all_data:\n",
    "    print(\"\\n⚠️ Error: No dataframes were loaded. Check file paths.\")\n",
    "else:\n",
    "    # 結合 (indexをリセット)\n",
    "    df_combined = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # 4. 結合したDataFrameをAUC_all.csvとして保存\n",
    "    output_file = \"AUC_all.csv\"\n",
    "    df_combined.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"\\n--- Output created ---\")\n",
    "    print(f\"✅ All AUC results combined into {output_file}.\")\n",
    "    print(f\"Total rows in {output_file}: {len(df_combined)}\")\n",
    "\n",
    "    # 結合されたデータの一部を表示\n",
    "    print(\"\\n--- AUC_all.csv Head (Sample Data) ---\")\n",
    "    print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b58b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# ========= 1. データ読み込みと準備 =========\n",
    "\n",
    "# 最終的に生成されたAUCサマリーファイル名を指定（必要に応じて変更してください）\n",
    "FILE_PATH = \"AUC_all.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {FILE_PATH}. Please run the previous code block to generate the CSV.\")\n",
    "    exit()\n",
    "\n",
    "# NaN値を含む行を削除し、AUC値が0.7未満のものは無視する\n",
    "df_filtered = df.dropna(subset=['AUC_bootstrap_mean'])\n",
    "df_filtered_plot = df_filtered[df_filtered['AUC_bootstrap_mean'] > 0.7].copy() # プロット対象（AUC>0.7）のみ\n",
    "\n",
    "# ========= 2. 特徴量の整形と色の定義 =========\n",
    "\n",
    "# 2.1. 特徴名のマッピングと結合\n",
    "def format_feature_name(row):\n",
    "    feature = row['Feature']\n",
    "    channel = row['Channel']\n",
    "    \n",
    "    # Amp_normをAmplitudeに改名\n",
    "    if feature == 'Amp_norm':\n",
    "        feature = 'Amplitude'\n",
    "        \n",
    "    # Pulse_Area_normはPulse_Areaと同一とみなし削除（Noneを返すことでフィルタリング）\n",
    "    if feature == 'Pulse_Area_norm':\n",
    "        return None\n",
    "        \n",
    "    # ChannelとFeatureを結合 \n",
    "    if channel in ['Red', 'IR']:\n",
    "        return f\"{channel}_{feature}\"\n",
    "    elif channel == 'Red/IR_Ratio':\n",
    "        # Ratioの場合はFeature名をそのまま使用（例: Red_IR_amp_norm_ratio）\n",
    "        return feature\n",
    "    return None\n",
    "\n",
    "df_filtered_plot['Combined_Feature'] = df_filtered_plot.apply(format_feature_name, axis=1)\n",
    "df_filtered_plot = df_filtered_plot.dropna(subset=['Combined_Feature'])\n",
    "\n",
    "# 2.2. 色の定義\n",
    "def get_feature_color(feature_name):\n",
    "    \"\"\"Red/IRに基づいて色を決定\"\"\"\n",
    "    feature_name = feature_name.lower()\n",
    "    if 'red' in feature_name:\n",
    "        return 'red'\n",
    "    elif 'ir' in feature_name:\n",
    "        return 'purple'\n",
    "    return 'black'\n",
    "\n",
    "# 2.3. ヒートマップ描画用データフレームの準備\n",
    "pair_order = [\n",
    "    'Normal vs Ischaemia',\n",
    "    'Normal vs Congestion',\n",
    "    'Ischaemia vs Congestion'\n",
    "]\n",
    "depth_order = sorted(df_filtered_plot['Depth'].unique())\n",
    "\n",
    "text_grid = {} # key: (Pair, Depth), value: [(text, color, auc_value), ...]\n",
    "heatmap_values = pd.DataFrame(index=pair_order, columns=depth_order, dtype=float)\n",
    "\n",
    "for index, row in df_filtered_plot.iterrows():\n",
    "    pair = row['Pair']\n",
    "    depth = row['Depth']\n",
    "    feature_name = row['Combined_Feature']\n",
    "    auc_value = row['AUC_bootstrap_mean']\n",
    "    \n",
    "    key = (pair, depth)\n",
    "    \n",
    "    # テキスト準備\n",
    "    text = f\"{feature_name}: {auc_value:.2f}\"\n",
    "    color = get_feature_color(feature_name)\n",
    "    \n",
    "    if key not in text_grid:\n",
    "        text_grid[key] = []\n",
    "    # (text, color, auc_value) のタプルでAUC値も格納\n",
    "    text_grid[key].append((text, color, auc_value))\n",
    "    \n",
    "    # 背景色の基準（セル内の最大AUC）を更新\n",
    "    if pair in pair_order and depth in depth_order:\n",
    "        current_max = heatmap_values.loc[pair, depth]\n",
    "        if pd.isna(current_max) or auc_value > current_max:\n",
    "            heatmap_values.loc[pair, depth] = auc_value\n",
    "\n",
    "\n",
    "# AUCが0.7未満（プロット対象外）のセルは、カラーマップの最小値（0.5）で埋める\n",
    "MIN_AUC_FOR_CMAP = 0.5 \n",
    "heatmap_values = heatmap_values.fillna(MIN_AUC_FOR_CMAP) \n",
    "\n",
    "# ========= 3. ヒートマップのプロット =========\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 4)) \n",
    "\n",
    "# 3.1. 背景色\n",
    "cmap = plt.cm.get_cmap('YlGnBu_r') \n",
    "norm = mcolors.Normalize(vmin=MIN_AUC_FOR_CMAP, vmax=1.0) \n",
    "\n",
    "cax = ax.imshow(heatmap_values.values, cmap=cmap, norm=norm, aspect='auto', interpolation='nearest')\n",
    "\n",
    "# 3.2. 軸の設定\n",
    "ax.set_xticks(np.arange(len(depth_order)))\n",
    "ax.set_yticks(np.arange(len(pair_order)))\n",
    "ax.set_xticklabels([f'{d} mm' for d in depth_order])\n",
    "ax.set_yticklabels(pair_order)\n",
    "\n",
    "ax.set_xlabel('Depth (mm)', fontsize=13)\n",
    "ax.set_ylabel('Pairwise Comparison', fontsize=13)\n",
    "ax.set_title(f'High AUC Features (Top 5)', fontsize=16, pad=20)\n",
    "\n",
    "# 3.3. テキストの描画\n",
    "for i, pair in enumerate(pair_order):\n",
    "    for j, depth in enumerate(depth_order):\n",
    "        key = (pair, depth)\n",
    "        \n",
    "        # AUC > 0.7のデータがあるセルのみにテキストを描画\n",
    "        if key in text_grid and heatmap_values.loc[pair, depth] > 0.7:\n",
    "            \n",
    "            # ★★★ 修正箇所: AUCで降順ソートし、上位5つに制限 ★★★\n",
    "            # text_grid[key] は [(text, color, auc_value), ...]\n",
    "            sorted_entries = sorted(text_grid[key], key=lambda x: x[2], reverse=True)\n",
    "            \n",
    "            # 上位5つの (text, color) のみを取得\n",
    "            top_5_entries = [(t, c) for t, c, a in sorted_entries[:5]] \n",
    "            \n",
    "            n_entries = len(top_5_entries)\n",
    "            \n",
    "            # 垂直方向の中心から上下にずらして配置を調整\n",
    "            # 5行まで対応するようにオフセットを調整\n",
    "            y_offsets = np.linspace(-0.35, 0.35, n_entries) if n_entries > 0 else []\n",
    "            \n",
    "            for k, (text, color) in enumerate(top_5_entries):\n",
    "                ax.text(j, i + y_offsets[k],\n",
    "                        text, \n",
    "                        ha=\"center\", \n",
    "                        va=\"center\", \n",
    "                        color=color, \n",
    "                        fontsize=8, \n",
    "                        linespacing=1.2)\n",
    "\n",
    "# 3.4. カラーバーの追加と修正\n",
    "cbar_ticks = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "cbar = fig.colorbar(cax, ticks=cbar_ticks, label='AUC Value')\n",
    "\n",
    "custom_labels = [f'{t:.1f}' for t in cbar_ticks]\n",
    "custom_labels[0] = f'≤ {MIN_AUC_FOR_CMAP:.1f}'\n",
    "\n",
    "cbar.ax.set_yticklabels(custom_labels) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
